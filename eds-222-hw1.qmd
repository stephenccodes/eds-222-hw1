---
title: "EDS 222: Homework 1"
date: "10/13/24"
author: "Stephen Carroll"
editor_options: 
  chunk_output_type: inline
execute: 
  warning: false
format: 
  html: 
    code-fold: true
---

## Background

*(The case study in this exercise is based on reality, but does not include actual observational data.)*

In this exercise we will look at a case study concerning air quality in South Asia. The World Health Organization estimates that air pollution kills an estimated seven million people per year, due to its effects on the cardiovascular and respiratory systems. Out of the 40 most polluted cities in the world, South Asia is home to 37, and Pakistan was ranked to contain the second most air pollution in the world in 2020 (IQAIR, 2020). In 2019, Lahore, Pakistan was the 12th most polluted city in the world, exposing a population of 11.1 million people to increased mortality and morbidity risks.

In this exercise, you are given two datasets from Lahore, Pakistan and are asked to compare the two different data collection strategies from this city. These data are:

-   Crowd-sourced data from air quality monitors located in people's homes. These data are voluntarily collected by individual households who choose to install a monitor in their home and upload their data for public access.

-   Official government data from monitors installed by government officials at selected locations across Lahore. There have been reports that government officials strategically locate monitors in locations with cleaner air in order to mitigate domestic and international pressure to clean up the air.

::: callout-note
All data for EDS 222 will be stored on the Taylor server, in the shared `/courses/eds-222/data/` directory. Please see material from EDS 214 on how to access and retrieve data from Taylor. These data are small; all compute can be handled locally. Thanks to Bren PhD student Fatiq Nadeem for assembling these data!
:::

In answering the following questions, please consider the lecture content from class on sampling strategies, as well as the material in Chapter 2 of [*Introduction to Modern Statistics*](https://openintro-ims.netlify.app/data-design). Include in your submission your version of this file "`eds-222-hw1.qmd`" and the rendered HTML output, each containing complete answers to all questions *as well as the associated code*. Questions with answers unsupported by the code will be marked incomplete. Showing your work this way will help you develop the habit of creating reproducible code.

## Assessment

### Question 1

Load the data from each source and label it as `crowdsourced` and `govt` accordingly.

``` {r}
# Load packages
library(here)
library(tidyverse)

# Read in data
crowdsourced <- readRDS(file.path("data", "HW1", "airpol-PK-crowdsourced.RDS"))
govt <- readRDS(file.path("data","HW1", "airpol-PK-govt.RDS"))
```

::: callout-warning
There's an implicit assumption about file organization in the code above. What is it? How can you make the code work?
:::

The implicit assumption is that the file path given matches my own, which it doesn't. To get the data to load properly, I had to add the sub-folder "HW1" to the file path.

1.  These dataframes have one row per pollution observation. How many pollution records are in each dataset?

The crowd-sourced dataset has 5,488 observations, while the government datatset only has 1960.

```{r}
# Find the number of rows in govt
gov_rows <- nrow(govt)

# Find the number of rows in crowdsourced
crowd_rows <- nrow(crowdsourced)

print(paste("There are", gov_rows, "records in the government datatset, and", crowd_rows, "records in the crowd-sourced dataset."))
```
2.  Each monitor is located at a unique latitude and longitude location. How many unique monitors are in each dataset?

There are 14 unique monitor sites in the crowd-sourced dataset and 5 in the govt dataset.

::: callout-tip
`group_by(longitude,latitude)` and `cur_group_id()` in `dplyr` will help in creating a unique identifier for each (longitude, latitude) pair.
:::

```{r}
# Make a new column that assigns a unique value to the latitude and longitude pairing
crowdsourced <- crowdsourced %>%
  group_by(longitude, latitude) %>%
  mutate(lat_long = cur_group_id()) %>%
  ungroup()

# Count the unique values
crowd_senseor_cnt <- length(unique(crowdsourced$lat_long))
```

```{r}
# Make a new column that assigns a unique value to the latitude and longitude pairing
govt <- govt %>%
  group_by(longitude, latitude) %>%
  mutate(lat_long = cur_group_id()) %>%
  ungroup()

# Count the unique values
gov_sensor_cnt <- length(unique(govt$lat_long))

print(paste(" There are", crowd_senseor_cnt, "unique monitor sites in the crowd-sourced dataset and", gov_sensor_cnt, "in the government dataset."))
```

### Question 2

The goal of pollution monitoring in Lahore is to measure the average pollution conditions across the city.

1.  What is the *population* in this setting? Please be precise.


The population in this setting is the air quality of the entire city in question, Lahore, Pakistan over the given time frame, 11/4/18 to 11/30/19.

2.  What are the *samples* in this setting? Please be precise.

The samples are two sets of measurements of airborne particulate matter in different geographic locations across Lahore, Pakistan, taken both by the government and crowd-sourced individuals. One sample is crowd-sourced and consists of data collected from households that voluntarily installed air quality monitors. the quantity and location of these household monitors represent the sample. The second sample is from government air quality monitors, installed in select locations in the city. Both samples measure the air quality of locations in Lahore from 11/4/18 to 11/30/19, but the locatoin and quantity of monitors used differs across the two samples.

```{r}
# Find the data collection time frame of the crowdsourced dataset
crowd_range <- range(crowdsourced$date)

# Find the data collection time frame of the govt dataset
govt_range <- range(govt$date)

print(paste("The date range for the crowd-sourced dataset is", crowd_range[1], "to", crowd_range[2], "and the date range for the government dataset is", govt_range[1], "to", govt_range[2]))
```

3.  These samples were not randomly collected from across locations in Lahore. Given the sampling approaches described above, discuss possible biases that may enter when we use these samples to construct estimates of population parameters.

The dataset from the government might have a selection bias in the sense that they may have chosen less polluted areas of the city to place their air quality sensors. They also may have chosen less locations to sample from and taken less samples as a whole. At a glance, the mean value of the 'PM' column in the government dataset is significantly lower than that of the same column in the crowd-sourced dataset.

The crowdsourced data may be biased as well due to self-selection bias, those who are aware of the air quality issue may be eager to volunteer to collect samples. It's also possible that the households who volunteered to collect air quality samples were not experts in collecting this type of data. Furthermore, low income areas tend to be less trusting of studies like this so the data may be collected by wealthy families who may be living in an area with better air quality. We also have no way of knowing how accurate the data is because the sampling methods are not standardized.


```{r}
# Find the mean of the 'PM' column for each datatset to compare them
crowd_mean <- round(mean(crowdsourced$PM), 2)
govt_mean <- round(mean(govt$PM), 2)

print(paste0("Crowd-sourced mean: ", crowd_mean, ", government mean: ", govt_mean, "."))
```
### Question 3

1.  For both the government data and the crowd-sourced data, report the sample mean, sample minimum, and sample maximum value of PM 2.5 (measured in $\mu g/m^3$).

For the crowdsourced dataset, the PM mean is 70.2, the max is 120, and the min is 20. For the the government dataset, the PM mean is 39.65, the max is 65, and the min is 15. 
```{r}
# Find the mean, max, and min for the 'PM' column in crowdsourced
crowd_max <- max(crowdsourced$PM)
crowd_min <- min(crowdsourced$PM)

print(paste0("For the crowd-sourced dataset, the PM mean is ", crowd_mean, ", the max is ", crowd_max, ", and the min is ", crowd_min, "."))
```

```{r}
# Find the mean, max, and min for the 'PM' column in govt
govt_max <- max(govt$PM)
govt_min <- min(govt$PM)

print(paste0("For the government dataset, the PM mean is ", govt_mean, ", the max is ", govt_max, ", and the min is ", govt_min, "."))
```
2.  Discuss any key differences that you see between these two samples.

The mean value for the government datatset are roughly half of that of the crowd-sourced dataset. Similarly, the max value for the government dataset has a value that is almost half as much as the one in crowd-sourced. The min value for both datatsets have less deviation, but the lower value is also found in the government dataset. Overall, it seems that the data taken by the government paints a vastly different picture than the data that has been crowd-sourced, which indicates high levels of pollution. 

3.  Are the differences in mean pollution as expected, given what we know about the sampling strategies?

Given that we know about the sampling bias, the differences in mean are expected. The data from the government that indicates lower levels of pollution than the crowd-sourced dataset. The government monitors were placed in conspicuously clean air areas, likely intentionally to obscure the severity of the problem. The crowdsourced data was collected by amateurs who have no experience with this type of data collection, potentially affecting the resulting measurements. It's also possible that the types of families that would volunteer to host an air quality monitor are more likely to be in wealthier areas, which may have cleaner air than poorer neighborhoods. Even though the mean is much higher than the government data, it may still be biased and not reflect an accurate representation of the air quality across Lahore in the given time frame.

XXXX Discuss BIAS

### Question 4

Use the location of the air pollution stations for both of the sampling strategies to generate a map showing locations of each observation. Color the two samples with different colors to highlight how each sample obtains measurements from different parts of the city.

::: callout-tip
`longitude` indicates location in the *x*-direction, while `latitude` indicates location in the *y*-direction. With `ggplot2` this should be nothing fancy. We'll do more spatial data in `R` later in the course.
:::

```{r}
# Plot both datatsets by latitude and longitude
# Color them according to each dataset
sensor_loc <- ggplot() +
  geom_point(data = crowdsourced, 
             aes(x = longitude,
                 y = latitude),
                 color = 'red') +
  geom_point(data = govt, 
             aes(x = longitude,
                 y = latitude),
                 color = 'blue') +
  labs(title = 'Latitude & Longitude of Air Quality Sensors in Lahore, Pakistan', x = 'Longitude (°)', y = 'Latitude (°)') +
  theme(plot.title = element_text(hjust = 0.5)) # Center the title

print(sensor_loc)
```


### Question 5

The local newspaper in Pakistan, *Dawn*, claims that the government is misreporting the air pollution levels in Lahore. Do the locations of monitors in question 4, relative to crowd-sourced monitors, suggest anything about a possible political bias?

Given that all five of the government sensors are clustered in a similar location, it appears that they were intentionally placed in an area with better air quality. The crowd sourced monitors are spread throughout the city and the data collected have significantly different values. 

### Question 6

Given the recent corruption in air quality reporting, the Prime Minister of Pakistan has hired an independent body of environmental data scientists to create an unbiased estimate of the mean PM 2.5 across Lahore using some combination of both government stations and crowd sourced observations.

NASA's satellite data indicates that the average PM across Lahore is 89.2 $\mu g/m^3$. Since this is the most objective estimate of population-level PM 2.5 available, your goal is to match this mean as closely as possible by creating a new ground-level monitoring sample that draws on both the government and crowd-sourced samples.

#### Question 6.1

First, generate a *random sample* of size $n=1000$ air pollution records by (i) pooling observations across the government and the crowd-sourced data; and (ii) drawing observations at random from this pooled sample.

::: callout-tip
`bind_rows()` may be helpful.
:::

```{r}
# Pool the data from both data frames together
comb_data <- bind_rows(crowdsourced, govt)

print(paste("Here is the new dataset that has pooled both the government and crowd-sourced data:"))

print(comb_data)
```


```{r}
# Create a subset of 'comb_data' with 1000 random observations
# Set seed for reproducibility
set.seed(454)
rand_samp <- comb_data %>%
  group_by() %>%
  slice_sample(n = 1000)

print(paste("Here is a new dataset with a random sample of 1000 observations drawn from the pooled dataset."))

print(rand_samp)
```

Second, create a *stratified random sample*. Do so by (i) stratifying your pooled data-set into strata of 0.01 degrees of latitude, and (ii) randomly sampling 200 air pollution observations from each stratum.

```{r}
# Round latitude to two decimal places in the 'comb_data' subset
comb_data <- comb_data %>%
  mutate(lat_stratum = round(latitude, 2))

# Create a subset that randomly samples 200 observations from 'comb_data'
# Set seed for reproducibility
set.seed(454)
strat_data <- comb_data %>%
  group_by(lat_stratum) %>%
  slice_sample(n = 200) %>%
  ungroup()

print(paste("Here is a stratified dataset with a random sample of 200 observations drawn from the pooled dataset."))

print(strat_data)
```

#### Question 6.2

Compare estimated means of PM 2.5 for each sampling strategy to the NASA estimate of 89.2 $\mu g/m^3$. Which sample seems to match the satellite data best? What would you recommend the Prime Minister do? Does your proposed sampling strategy rely more on government or on crowd-sourced data? Why might that be the case?

```{r}
# Find the mean of the stratified sample
strat_mean <- round(mean(strat_data$PM), 2)

print(paste0("The mean of the stratified data is ", strat_mean, "."))

# Find the mean of the random sample
comb_mean <- round(mean(comb_data$PM), 2)

print(paste0("The mean of the random sample is ", comb_mean, "."))

```
The stratified sample mean is 66.24 $\mu g/m^3$, and appears to be closer to the NASA estimate of 89.2 $\mu g/m^3$ than a random sample, which yielded a mean of 62.16 $\mu g/m^3$. This is because grouping the data by similar latitude reduces the bias of the government sensors, which are all from a similar latitude.

Based on these results, I would recommend that the Prime Minister use stratified sampling techniques as opposed to random sampling. Better yet, use the data that NASA provides since it is the most accurate and objective.

Because all of the government sampling locations are in a very tight cluster geographically, using random strata of data based on latitude reduces the likelihood that these biased observations influence the sample mean. There are far more observations from latitude strata other than the few that include the government sensors, so the stratified sampling method relies more on the crowd-sourced data.






